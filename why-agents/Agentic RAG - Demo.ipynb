{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0252b08",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de9bcd",
   "metadata": {},
   "source": [
    "!pip install smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b73e9a",
   "metadata": {},
   "source": [
    "## Utility Functions and Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009fb31",
   "metadata": {},
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a46c5a",
   "metadata": {},
   "source": [
    "## Implementation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8290b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishavchandravarma/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Building the Knowledge Base.\n",
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
    "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]}) for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e856e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishavchandravarma/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/rishavchandravarma/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <F6236B89-E4CA-3330-B665-E463D537EAF3> /Users/rishavchandravarma/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <552B36CA-07A6-332B-BF7F-6D22D9005F71> /Users/rishavchandravarma/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up the retriever tool.\n",
    "from smolagents import Tool\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(docs, k=10)\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c521b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising the agent.\n",
    "from smolagents import CodeAgent, HfApiModel\n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)\n",
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool],\n",
    "    model=HfApiModel(),\n",
    "    max_steps=4,\n",
    "    verbosity_level=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fa345e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">For a transformers model training, which is slower, the forward or the backward pass?</span>                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFor a transformers model training, which is slower, the forward or the backward pass?\u001b[0m                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Output message of the LLM:</span> ────────────────────────────────────────────────────────────────────────────────────────\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: To determine which is slower between the forward and backward passes in a transformers model training, I </span><span style=\"background-color: #0d1117\"> </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">need to gather relevant information from the transformers documentation.</span><span style=\"background-color: #0d1117\">                                           </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">forward_pass_info </span><span style=\"color: #ff7b72; text-decoration-color: #ff7b72; background-color: #0d1117; font-weight: bold\">=</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> retriever(query</span><span style=\"color: #ff7b72; text-decoration-color: #ff7b72; background-color: #0d1117; font-weight: bold\">=</span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">\"forward pass in transformers\"</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">)</span><span style=\"background-color: #0d1117\">                                                </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">backward_pass_info </span><span style=\"color: #ff7b72; text-decoration-color: #ff7b72; background-color: #0d1117; font-weight: bold\">=</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> retriever(query</span><span style=\"color: #ff7b72; text-decoration-color: #ff7b72; background-color: #0d1117; font-weight: bold\">=</span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">\"backward pass in transformers\"</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">)</span><span style=\"background-color: #0d1117\">                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">print(</span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">\"Forward pass info:\"</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">, forward_pass_info)</span><span style=\"background-color: #0d1117\">                                                                     </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">print(</span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">\"Backward pass info:\"</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">, backward_pass_info)</span><span style=\"background-color: #0d1117\">                                                                   </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">```</span><span style=\"background-color: #0d1117\">                                                                                                                </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">&lt;end_code&gt;</span><span style=\"background-color: #0d1117\">                                                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mOutput message of the LLM:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mTo\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdetermine\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwhich\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslower\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbetween\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpasses\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtraining,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mneed\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mgather\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mrelevant\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfrom\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdocumentation.\u001b[0m\u001b[48;2;13;17;23m                                           \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23m```\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mpy\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mforward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[1;38;2;255;123;114;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretriever\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mquery\u001b[0m\u001b[1;38;2;255;123;114;48;2;13;17;23m=\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mforward pass in transformers\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                                \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mbackward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[1;38;2;255;123;114;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretriever\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mquery\u001b[0m\u001b[1;38;2;255;123;114;48;2;13;17;23m=\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mbackward pass in transformers\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mprint\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mForward pass info:\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                                                     \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mprint\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mBackward pass info:\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                                                   \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23m```\u001b[0m\u001b[48;2;13;17;23m                                                                                                                \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m<end_code>\u001b[0m\u001b[48;2;13;17;23m                                                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing this code:</span> ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">forward_pass_info </span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"forward pass in transformers\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">backward_pass_info </span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward pass in transformers\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                          </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Forward pass info:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, forward_pass_info)</span><span style=\"background-color: #272822\">                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Backward pass info:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, backward_pass_info)</span><span style=\"background-color: #272822\">                                                               </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting this code:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mforward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mforward pass in transformers\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mbackward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward pass in transformers\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                          \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mForward pass info:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mforward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mBackward pass info:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbackward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "Forward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n",
       "\n",
       "model(**model_inputs)  # forward pass\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "===== Document 1 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 2 =====\n",
       "layer is falsely activated during the forward pass, *i.e.* pass *self.training* to [PyTorch's functional \n",
       "dropout](https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout)\n",
       "\n",
       "===== Document 3 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 4 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 5 =====\n",
       "&gt;&gt;&gt; model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
       "&gt;&gt;&gt; # forward pass\n",
       "&gt;&gt;&gt; model(**inputs)\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "  While generating the target text set the `decoder_start_token_id` to the target language id. The following\n",
       "  example shows how to translate English to Romanian using the *facebook/mbart-large-en-ro* model.\n",
       "\n",
       "```python\n",
       "&gt;&gt;&gt; from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
       "\n",
       "===== Document 6 =====\n",
       "This time we would illustrate the object `model_flax` without the weight matrices:\n",
       "\n",
       "![alt text](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/lm_flax_def.png)\n",
       "\n",
       "\n",
       "Accordingly, the forward pass requires both `input_ids` as well as a dictionary consisting of the model's weights \n",
       "(called `state` here) to compute the `sequences`:\n",
       "\n",
       "To get the initial `state` we need to explicitly do a forward pass by passing a dummy input:\n",
       "\n",
       "===== Document 7 =====\n",
       "to implement BigBird.\n",
       "- The first goal should be to successfully run a forward pass using the RoBERTa checkpoint \n",
       "`bigbr_base/model.ckpt-0.data-00000-of-00001` and `bigbr_base/model.ckpt-0.index`.\n",
       "\n",
       "===== Document 8 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 9 =====\n",
       "- For languages with a Roman alphabet, such as English or French, the tokenizer can be used directly to \n",
       "pre-process the text inputs. The following code example runs a forward pass using the MMS-TTS English checkpoint:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import VitsTokenizer, VitsModel, set_seed\n",
       "\n",
       "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "Backward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 3 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 4 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 5 =====\n",
       "```py\n",
       "&gt;&gt;&gt; from transformers import AutoTokenizer\n",
       "\n",
       "&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
       "```\n",
       "\n",
       "Then pass your text to the tokenizer:\n",
       "\n",
       "===== Document 6 =====\n",
       "## How to benchmark 🤗 Transformers models\n",
       "\n",
       "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark 🤗 Transformers models. \n",
       "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
       "_training_.\n",
       "\n",
       "&lt;Tip&gt;\n",
       "\n",
       "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
       "backward pass.\n",
       "\n",
       "&lt;/Tip&gt;\n",
       "\n",
       "===== Document 7 =====\n",
       "- Avoid storing the intermediate results of each layer by using reversible transformer layers to obtain them during\n",
       "the backward pass (subtracting the residuals from the input of the next layer gives them back) or recomputing them \n",
       "for results inside a given layer (less efficient than storing them but saves memory).\n",
       "- Compute the feedforward operations by chunks and not on the whole batch.\n",
       "\n",
       "===== Document 8 =====\n",
       "```python\n",
       "&gt;&gt;&gt; from transformers import AutoConfig, MusicgenForCausalLM, MusicgenForConditionalGeneration\n",
       "\n",
       "&gt;&gt;&gt; # Option 1: get decoder config and pass to `.from_pretrained`\n",
       "&gt;&gt;&gt; decoder_config = AutoConfig.from_pretrained(\"facebook/musicgen-small\").decoder\n",
       "&gt;&gt;&gt; decoder = MusicgenForCausalLM.from_pretrained(\"facebook/musicgen-small\", **decoder_config)\n",
       "\n",
       "===== Document 9 =====\n",
       "This way each of the 3 GPUs gets the full tensors reconstructed and makes a forward pass with its own mini-batch.\n",
       "As soon as the calculation is done, the data that is no longer needed gets dropped - it's only used during the \n",
       "calculation. \n",
       "The reconstruction is done efficiently via a pre-fetch.\n",
       "\n",
       "Then the whole process is repeated for layer Lb, then Lc forward-wise, and then backward Lc -&gt; Lb -&gt; La.\n",
       "\n",
       "&lt;Tip&gt;\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "Forward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n",
       "\n",
       "model(**model_inputs)  # forward pass\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "===== Document 1 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 2 =====\n",
       "layer is falsely activated during the forward pass, *i.e.* pass *self.training* to [PyTorch's functional \n",
       "dropout](https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout)\n",
       "\n",
       "===== Document 3 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 4 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 5 =====\n",
       ">>> model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
       ">>> # forward pass\n",
       ">>> model(**inputs)\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "  While generating the target text set the `decoder_start_token_id` to the target language id. The following\n",
       "  example shows how to translate English to Romanian using the *facebook/mbart-large-en-ro* model.\n",
       "\n",
       "```python\n",
       ">>> from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
       "\n",
       "===== Document 6 =====\n",
       "This time we would illustrate the object `model_flax` without the weight matrices:\n",
       "\n",
       "![alt text](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/lm_flax_def.png)\n",
       "\n",
       "\n",
       "Accordingly, the forward pass requires both `input_ids` as well as a dictionary consisting of the model's weights \n",
       "(called `state` here) to compute the `sequences`:\n",
       "\n",
       "To get the initial `state` we need to explicitly do a forward pass by passing a dummy input:\n",
       "\n",
       "===== Document 7 =====\n",
       "to implement BigBird.\n",
       "- The first goal should be to successfully run a forward pass using the RoBERTa checkpoint \n",
       "`bigbr_base/model.ckpt-0.data-00000-of-00001` and `bigbr_base/model.ckpt-0.index`.\n",
       "\n",
       "===== Document 8 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 9 =====\n",
       "- For languages with a Roman alphabet, such as English or French, the tokenizer can be used directly to \n",
       "pre-process the text inputs. The following code example runs a forward pass using the MMS-TTS English checkpoint:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import VitsTokenizer, VitsModel, set_seed\n",
       "\n",
       "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "Backward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 3 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 4 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 5 =====\n",
       "```py\n",
       ">>> from transformers import AutoTokenizer\n",
       "\n",
       ">>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
       "```\n",
       "\n",
       "Then pass your text to the tokenizer:\n",
       "\n",
       "===== Document 6 =====\n",
       "## How to benchmark 🤗 Transformers models\n",
       "\n",
       "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark 🤗 Transformers models. \n",
       "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
       "_training_.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
       "backward pass.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "===== Document 7 =====\n",
       "- Avoid storing the intermediate results of each layer by using reversible transformer layers to obtain them during\n",
       "the backward pass (subtracting the residuals from the input of the next layer gives them back) or recomputing them \n",
       "for results inside a given layer (less efficient than storing them but saves memory).\n",
       "- Compute the feedforward operations by chunks and not on the whole batch.\n",
       "\n",
       "===== Document 8 =====\n",
       "```python\n",
       ">>> from transformers import AutoConfig, MusicgenForCausalLM, MusicgenForConditionalGeneration\n",
       "\n",
       ">>> # Option 1: get decoder config and pass to `.from_pretrained`\n",
       ">>> decoder_config = AutoConfig.from_pretrained(\"facebook/musicgen-small\").decoder\n",
       ">>> decoder = MusicgenForCausalLM.from_pretrained(\"facebook/musicgen-small\", **decoder_config)\n",
       "\n",
       "===== Document 9 =====\n",
       "This way each of the 3 GPUs gets the full tensors reconstructed and makes a forward pass with its own mini-batch.\n",
       "As soon as the calculation is done, the data that is no longer needed gets dropped - it's only used during the \n",
       "calculation. \n",
       "The reconstruction is done efficiently via a pre-fetch.\n",
       "\n",
       "Then the whole process is repeated for layer Lb, then Lc forward-wise, and then backward Lc -> Lb -> La.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 3.42 seconds| Input tokens: 2,099 | Output tokens: 88]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 3.42 seconds| Input tokens: 2,099 | Output tokens: 88]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Output message of the LLM:</span> ────────────────────────────────────────────────────────────────────────────────────────\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: From the retrieved information, it seems that the backward pass generally takes longer than the forward </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">pass, as it involves additional computations for gradient calculation and often involves reading more data. The </span><span style=\"background-color: #0d1117\">   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">text mentions that for convolutions and linear layers, the backward pass can be approximately twice as slow as the </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">forward pass. Additionally, the forward pass can be optimized by storing intermediate results, whereas the backward</span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">pass typically requires recomputing these results, which can introduce additional computational overhead. </span><span style=\"background-color: #0d1117\">         </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Given this information, I can conclude that the backward pass is generally slower than the forward pass in </span><span style=\"background-color: #0d1117\">        </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">transformers model training. </span><span style=\"background-color: #0d1117\">                                                                                      </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Now, I will provide the final answer.</span><span style=\"background-color: #0d1117\">                                                                              </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">final_answer(\"backward pass\")</span><span style=\"background-color: #0d1117\">                                                                                      </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```&lt;end_code&gt;</span><span style=\"background-color: #0d1117\">                                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mOutput message of the LLM:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mFrom\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretrieved\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mit\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mseems\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mgenerally\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtakes\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlonger\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mpass,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mit\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minvolves\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23madditional\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcomputations\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mgradient\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcalculation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moften\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minvolves\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mreading\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmore\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdata.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mThe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mtext\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmentions\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconvolutions\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlinear\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlayers,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mapproximately\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtwice\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslow\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mAdditionally,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moptimized\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mby\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mstoring\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mintermediate\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mresults,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwhereas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtypically\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mrequires\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mrecomputing\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthese\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mresults,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwhich\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mintroduce\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23madditional\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcomputational\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moverhead.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m         \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mGiven\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconclude\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mgenerally\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslower\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m        \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtraining.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m                                                                                      \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mNow,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mprovide\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfinal\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23manswer.\u001b[0m\u001b[48;2;13;17;23m                                                                              \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```py\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mfinal_answer(\"backward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\")\u001b[0m\u001b[48;2;13;17;23m                                                                                      \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```<end_code>\u001b[0m\u001b[48;2;13;17;23m                                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing this code:</span> ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward pass\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting this code:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward pass\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: backward pass</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: backward pass\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.48 seconds| Input tokens: 5,878 | Output tokens: 231]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.48 seconds| Input tokens: 5,878 | Output tokens: 231]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "backward pass\n"
     ]
    }
   ],
   "source": [
    "## agent calling.\n",
    "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59deadcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
